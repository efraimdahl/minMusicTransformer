{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import tqdm\n",
    "import muspy\n",
    "import src.utils as utils\n",
    "import src.representation as representation\n",
    "import src.dataset as dataset\n",
    "import src.music_x_transformers as music_x_transformers\n",
    "import pathlib\n",
    "import src.advUtils as advUtils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load configurations\n",
    "train_args = utils.load_json(\".\\pre_trained_models\\mmt_sod_ape_training_logs.json\")\n",
    "encoding = representation.load_encoding(\"encoding.json\")\n",
    "\n",
    "sos = encoding[\"type_code_map\"][\"start-of-song\"]\n",
    "eos = encoding[\"type_code_map\"][\"end-of-song\"]\n",
    "beat_0 = encoding[\"beat_code_map\"][0]\n",
    "beat_4 = encoding[\"beat_code_map\"][4]\n",
    "beat_16 = encoding[\"beat_code_map\"][16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 12\n",
      "12 12\n"
     ]
    }
   ],
   "source": [
    "# Load training/testing/demo Data\n",
    "testdata = advUtils.convert_extract_load(train_args,encoding, json_dir = \"./data/test/json\",repr_dir=\"./data/test/repr\")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    testdata,\n",
    "    shuffle=True,\n",
    "    num_workers=1,\n",
    "    collate_fn=dataset.MusicDataset.collate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the pretrained model weights\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MusicXTransformer(\n",
       "  (decoder): MusicAutoregressiveWrapper(\n",
       "    (net): MusicTransformerWrapper(\n",
       "      (token_emb): ModuleList(\n",
       "        (0): TokenEmbedding(\n",
       "          (emb): Embedding(5, 512)\n",
       "        )\n",
       "        (1): TokenEmbedding(\n",
       "          (emb): Embedding(257, 512)\n",
       "        )\n",
       "        (2): TokenEmbedding(\n",
       "          (emb): Embedding(13, 512)\n",
       "        )\n",
       "        (3): TokenEmbedding(\n",
       "          (emb): Embedding(129, 512)\n",
       "        )\n",
       "        (4): TokenEmbedding(\n",
       "          (emb): Embedding(33, 512)\n",
       "        )\n",
       "        (5): TokenEmbedding(\n",
       "          (emb): Embedding(65, 512)\n",
       "        )\n",
       "      )\n",
       "      (pos_emb): AbsolutePositionalEmbedding(\n",
       "        (emb): Embedding(1024, 512)\n",
       "      )\n",
       "      (emb_dropout): Dropout(p=0.2, inplace=False)\n",
       "      (project_emb): Identity()\n",
       "      (attn_layers): Decoder(\n",
       "        (layers): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (1): None\n",
       "              (2): None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.2, inplace=False)\n",
       "              (to_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (1): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (1): None\n",
       "              (2): None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (1): GELU()\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.2, inplace=False)\n",
       "                (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (2): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (1): None\n",
       "              (2): None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.2, inplace=False)\n",
       "              (to_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (3): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (1): None\n",
       "              (2): None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (1): GELU()\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.2, inplace=False)\n",
       "                (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (4): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (1): None\n",
       "              (2): None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.2, inplace=False)\n",
       "              (to_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (5): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (1): None\n",
       "              (2): None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (1): GELU()\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.2, inplace=False)\n",
       "                (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (6): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (1): None\n",
       "              (2): None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.2, inplace=False)\n",
       "              (to_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (7): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (1): None\n",
       "              (2): None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (1): GELU()\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.2, inplace=False)\n",
       "                (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (8): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (1): None\n",
       "              (2): None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.2, inplace=False)\n",
       "              (to_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (9): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (1): None\n",
       "              (2): None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (1): GELU()\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.2, inplace=False)\n",
       "                (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (10): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (1): None\n",
       "              (2): None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.2, inplace=False)\n",
       "              (to_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (11): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (1): None\n",
       "              (2): None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (1): GELU()\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.2, inplace=False)\n",
       "                (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (to_logits): ModuleList(\n",
       "        (0): Linear(in_features=512, out_features=5, bias=True)\n",
       "        (1): Linear(in_features=512, out_features=257, bias=True)\n",
       "        (2): Linear(in_features=512, out_features=13, bias=True)\n",
       "        (3): Linear(in_features=512, out_features=129, bias=True)\n",
       "        (4): Linear(in_features=512, out_features=33, bias=True)\n",
       "        (5): Linear(in_features=512, out_features=65, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model\n",
    "device = torch.device(\"cpu\")\n",
    "print(f\"Creating the model...\")\n",
    "model = music_x_transformers.MusicXTransformer(\n",
    "    dim=train_args[\"dim\"],\n",
    "    encoding=encoding,\n",
    "    depth=train_args[\"layers\"],\n",
    "    heads=train_args[\"heads\"],\n",
    "    max_seq_len=train_args[\"max_seq_len\"],\n",
    "    max_beat=train_args[\"max_beat\"],\n",
    "    rotary_pos_emb=train_args[\"rel_pos_emb\"],\n",
    "    use_abs_pos_emb=train_args[\"abs_pos_emb\"],\n",
    "    emb_dropout=train_args[\"dropout\"],\n",
    "    attn_dropout=train_args[\"dropout\"],\n",
    "    ff_dropout=train_args[\"dropout\"],\n",
    ").to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(\"./pre_trained_models/mmt_sod_ape_best_model.pt\", map_location=device))\n",
    "print(f\"Loaded the pretrained model weights\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(n,sample_dir,modes=[\"unconditioned\"],seq_len=1024,temperature=1,filter_logits=\"top_k\",filter_thresh=0.9):\n",
    "    with torch.no_grad():\n",
    "        data_iter = iter(test_loader)\n",
    "        for i in tqdm.tqdm(range(n), ncols=80):\n",
    "            batch = next(data_iter)\n",
    "            print(\"Generating based on\",batch['name'])\n",
    "            for mode in modes:\n",
    "                if(mode==\"unconditioned\"):\n",
    "                    tgt_start = torch.zeros((1, 1, 6), dtype=torch.long, device=device)\n",
    "                    tgt_start[:, 0, 0] = sos\n",
    "                elif(mode==\"instrument_informed\"):\n",
    "                    prefix_len = int(np.argmax(batch[\"seq\"][0, :, 1] >= beat_0))\n",
    "                    tgt_start = batch[\"seq\"][:1, :prefix_len].to(device)\n",
    "                elif(mode==\"4_beat\"):\n",
    "                    cond_len = int(np.argmax(batch[\"seq\"][0, :, 1] >= beat_4))\n",
    "                    tgt_start = batch[\"seq\"][:1, :cond_len].to(device)\n",
    "                elif(mode==\"16_beat\"):\n",
    "                    cond_len = int(np.argmax(batch[\"seq\"][0, :, 1] >= beat_16))\n",
    "                    tgt_start = batch[\"seq\"][:1, :cond_len].to(device)\n",
    "                # Generate new samples\n",
    "                generated = model.generate(\n",
    "                    tgt_start,\n",
    "                    seq_len,\n",
    "                    eos_token=eos,\n",
    "                    temperature=temperature,\n",
    "                    filter_logits_fn=filter_logits,\n",
    "                    filter_thres=filter_thresh,\n",
    "                    monotonicity_dim=(\"type\", \"beat\"),\n",
    "                )\n",
    "                generated_np = torch.cat((tgt_start, generated), 1).cpu().numpy()\n",
    "\n",
    "                # Save the results\n",
    "                advUtils.save_result(\n",
    "                    f\"{i}_{mode}\", generated_np[0], sample_dir, encoding,savecsv=False,savetxt=False,savenpy=False,savepng=False,savejson=False\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating based on ['anglebert_fugue_3_(c)mccoy']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████▌                      | 1/2 [00:39<00:39, 39.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating based on ['albinoni_sonate_da_chiesa_6_(c)icking-archive']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [01:03<00:00, 31.54s/it]\n"
     ]
    }
   ],
   "source": [
    "#Test generation\n",
    "generate(2,\"./samples\",seq_len=50,modes=[\"unconditioned\",\"instrument_informed\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Transfer Learning</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mtmt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
