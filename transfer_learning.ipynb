{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import tqdm\n",
    "import muspy\n",
    "import src.utils as utils\n",
    "import src.representation as representation\n",
    "import src.dataset as dataset\n",
    "import src.music_x_transformers as music_x_transformers\n",
    "import pathlib\n",
    "import src.advUtils as advUtils\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load configurations\n",
    "train_args = utils.load_json(\".\\pre_trained_models\\mmt_sod_ape_training_logs.json\")\n",
    "encoding = representation.load_encoding(\"encoding.json\")\n",
    "\n",
    "sos = encoding[\"type_code_map\"][\"start-of-song\"]\n",
    "eos = encoding[\"type_code_map\"][\"end-of-song\"]\n",
    "beat_0 = encoding[\"beat_code_map\"][0]\n",
    "beat_4 = encoding[\"beat_code_map\"][4]\n",
    "beat_16 = encoding[\"beat_code_map\"][16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training/testing/demo Data\n",
    "data_set = advUtils.convert_extract_load(train_args,encoding, json_dir = \"./data/test/json\",repr_dir=\"./data/test/repr\")\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    data_set,\n",
    "    shuffle=True,\n",
    "    num_workers=1,\n",
    "    collate_fn=dataset.MusicDataset.collate,\n",
    ")\n",
    "\n",
    "test_loader = data_loader\n",
    "train_loader = data_loader\n",
    "valid_loader = data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the model...\n",
      "Loaded the pretrained model weights\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MusicXTransformer(\n",
       "  (decoder): MusicAutoregressiveWrapper(\n",
       "    (net): MusicTransformerWrapper(\n",
       "      (token_emb): ModuleList(\n",
       "        (0): TokenEmbedding(\n",
       "          (emb): Embedding(5, 512)\n",
       "        )\n",
       "        (1): TokenEmbedding(\n",
       "          (emb): Embedding(257, 512)\n",
       "        )\n",
       "        (2): TokenEmbedding(\n",
       "          (emb): Embedding(13, 512)\n",
       "        )\n",
       "        (3): TokenEmbedding(\n",
       "          (emb): Embedding(129, 512)\n",
       "        )\n",
       "        (4): TokenEmbedding(\n",
       "          (emb): Embedding(33, 512)\n",
       "        )\n",
       "        (5): TokenEmbedding(\n",
       "          (emb): Embedding(65, 512)\n",
       "        )\n",
       "      )\n",
       "      (pos_emb): AbsolutePositionalEmbedding(\n",
       "        (emb): Embedding(1024, 512)\n",
       "      )\n",
       "      (emb_dropout): Dropout(p=0.2, inplace=False)\n",
       "      (project_emb): Identity()\n",
       "      (attn_layers): Decoder(\n",
       "        (layers): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (1): None\n",
       "              (2): None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.2, inplace=False)\n",
       "              (to_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (1): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (1): None\n",
       "              (2): None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (1): GELU()\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.2, inplace=False)\n",
       "                (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (2): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (1): None\n",
       "              (2): None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.2, inplace=False)\n",
       "              (to_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (3): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (1): None\n",
       "              (2): None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (1): GELU()\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.2, inplace=False)\n",
       "                (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (4): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (1): None\n",
       "              (2): None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.2, inplace=False)\n",
       "              (to_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (5): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (1): None\n",
       "              (2): None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (1): GELU()\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.2, inplace=False)\n",
       "                (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (6): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (1): None\n",
       "              (2): None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.2, inplace=False)\n",
       "              (to_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (7): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (1): None\n",
       "              (2): None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (1): GELU()\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.2, inplace=False)\n",
       "                (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (8): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (1): None\n",
       "              (2): None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.2, inplace=False)\n",
       "              (to_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (9): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (1): None\n",
       "              (2): None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (1): GELU()\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.2, inplace=False)\n",
       "                (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (10): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (1): None\n",
       "              (2): None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.2, inplace=False)\n",
       "              (to_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (11): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (1): None\n",
       "              (2): None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (1): GELU()\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.2, inplace=False)\n",
       "                (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (to_logits): ModuleList(\n",
       "        (0): Linear(in_features=512, out_features=5, bias=True)\n",
       "        (1): Linear(in_features=512, out_features=257, bias=True)\n",
       "        (2): Linear(in_features=512, out_features=13, bias=True)\n",
       "        (3): Linear(in_features=512, out_features=129, bias=True)\n",
       "        (4): Linear(in_features=512, out_features=33, bias=True)\n",
       "        (5): Linear(in_features=512, out_features=65, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model\n",
    "device = torch.device(\"cpu\")\n",
    "print(f\"Creating the model...\")\n",
    "model = music_x_transformers.MusicXTransformer(\n",
    "    dim=train_args[\"dim\"],\n",
    "    encoding=encoding,\n",
    "    depth=train_args[\"layers\"],\n",
    "    heads=train_args[\"heads\"],\n",
    "    max_seq_len=train_args[\"max_seq_len\"],\n",
    "    max_beat=train_args[\"max_beat\"],\n",
    "    rotary_pos_emb=train_args[\"rel_pos_emb\"],\n",
    "    use_abs_pos_emb=train_args[\"abs_pos_emb\"],\n",
    "    emb_dropout=train_args[\"dropout\"],\n",
    "    attn_dropout=train_args[\"dropout\"],\n",
    "    ff_dropout=train_args[\"dropout\"],\n",
    ").to(device)\n",
    "\n",
    "origModel = music_x_transformers.MusicXTransformer(\n",
    "    dim=train_args[\"dim\"],\n",
    "    encoding=encoding,\n",
    "    depth=train_args[\"layers\"],\n",
    "    heads=train_args[\"heads\"],\n",
    "    max_seq_len=train_args[\"max_seq_len\"],\n",
    "    max_beat=train_args[\"max_beat\"],\n",
    "    rotary_pos_emb=train_args[\"rel_pos_emb\"],\n",
    "    use_abs_pos_emb=train_args[\"abs_pos_emb\"],\n",
    "    emb_dropout=train_args[\"dropout\"],\n",
    "    attn_dropout=train_args[\"dropout\"],\n",
    "    ff_dropout=train_args[\"dropout\"],\n",
    ").to(device)\n",
    "\n",
    "firstTrain = model\n",
    "origModel.load_state_dict(torch.load(\"./pre_trained_models/mmt_sod_ape_best_model.pt\", map_location=device))\n",
    "model.load_state_dict(torch.load(\"./pre_trained_models/mmt_sod_ape_best_model.pt\", map_location=device))\n",
    "\n",
    "print(f\"Loaded the pretrained model weights\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(n,sample_dir,model=model,modes=[\"unconditioned\"],seq_len=1024,temperature=1,filter_logits=\"top_k\",filter_thresh=0.9):\n",
    "    with torch.no_grad():\n",
    "        data_iter = iter(test_loader)\n",
    "        for i in tqdm.tqdm(range(n), ncols=80):\n",
    "            batch = next(data_iter)\n",
    "            print(\"Generating based on\",batch['name'])\n",
    "            for mode in modes:\n",
    "                if(mode==\"unconditioned\"):\n",
    "                    tgt_start = torch.zeros((1, 1, 6), dtype=torch.long, device=device)\n",
    "                    tgt_start[:, 0, 0] = sos\n",
    "                elif(mode==\"instrument_informed\"):\n",
    "                    prefix_len = int(np.argmax(batch[\"seq\"][0, :, 1] >= beat_0))\n",
    "                    tgt_start = batch[\"seq\"][:1, :prefix_len].to(device)\n",
    "                elif(mode==\"4_beat\"):\n",
    "                    cond_len = int(np.argmax(batch[\"seq\"][0, :, 1] >= beat_4))\n",
    "                    tgt_start = batch[\"seq\"][:1, :cond_len].to(device)\n",
    "                elif(mode==\"16_beat\"):\n",
    "                    cond_len = int(np.argmax(batch[\"seq\"][0, :, 1] >= beat_16))\n",
    "                    tgt_start = batch[\"seq\"][:1, :cond_len].to(device)\n",
    "                # Generate new samples\n",
    "                generated = model.generate(\n",
    "                    tgt_start,\n",
    "                    seq_len,\n",
    "                    eos_token=eos,\n",
    "                    temperature=temperature,\n",
    "                    filter_logits_fn=filter_logits,\n",
    "                    filter_thres=filter_thresh,\n",
    "                    monotonicity_dim=(\"type\", \"beat\"),\n",
    "                )\n",
    "                generated_np = torch.cat((tgt_start, generated), 1).cpu().numpy()\n",
    "\n",
    "                # Save the results\n",
    "                advUtils.save_result(\n",
    "                    f\"{i}_{mode}\", generated_np[0], sample_dir, encoding,savecsv=False,savetxt=False,savenpy=False,savepng=False,savejson=False\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test generation\n",
    "#generate(2,\"./samples\",seq_len=50,modes=[\"unconditioned\",\"instrument_informed\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Transfer Learning</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Linear(in_features=512, out_features=5, bias=True)\n",
       "  (1): Linear(in_features=512, out_features=257, bias=True)\n",
       "  (2): Linear(in_features=512, out_features=13, bias=True)\n",
       "  (3): Linear(in_features=512, out_features=129, bias=True)\n",
       "  (4): Linear(in_features=512, out_features=33, bias=True)\n",
       "  (5): Linear(in_features=512, out_features=65, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.decoder.net.to_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleList(\n",
      "  (0): Linear(in_features=512, out_features=5, bias=True)\n",
      "  (1): Linear(in_features=512, out_features=257, bias=True)\n",
      "  (2): Linear(in_features=512, out_features=13, bias=True)\n",
      "  (3): Linear(in_features=512, out_features=129, bias=True)\n",
      "  (4): Linear(in_features=512, out_features=33, bias=True)\n",
      "  (5): Linear(in_features=512, out_features=65, bias=True)\n",
      ")\n",
      "Number of parameters: 19944950\n",
      "Number of trainable parameters: 257526\n"
     ]
    }
   ],
   "source": [
    "#Freeze All network layers\n",
    "for m in model.parameters():\n",
    "    m.requires_grad = False\n",
    "\n",
    "new_heads = model.decoder.net.to_logits\n",
    "new_heads.requires_grad = True\n",
    "\n",
    "for child in new_heads.children():\n",
    "    child.reset_parameters()\n",
    "    for param in child.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "print(model.decoder.net.to_logits)\n",
    "\n",
    "# layers_to_unfreeze = [\"decoder.net.to_logits.5.weight\",\"decoder.net.to_logits.4.weight\",\"decoder.net.to_logits.3.weight\",\"decoder.net.to_logits.2.weight\",\"decoder.net.to_logits.1.weight\",\"decoder.net.to_logits.0.weight\",\"decoder.net.norm.weight\"]\n",
    "\n",
    "# for m in model.named_parameters():\n",
    "#     state_dict = model.state_dict()\n",
    "#     if(m[0] in layers_to_unfreeze):\n",
    "#       newLayer = torch.rand(m[1].shape,requires_grad=True)\n",
    "#       if(m[0]==\"decoder.net.norm.weight\"):\n",
    "#          newLayer=torch.add(newLayer,1)\n",
    "#       else:\n",
    "#          newLayer=torch.add(newLayer,-0.5)\n",
    "#       state_dict[m[0]] = newLayer\n",
    "#       model.load_state_dict(state_dict)\n",
    "\n",
    "# for m in model.named_parameters():\n",
    "#     if(m[0] in layers_to_unfreeze):\n",
    "#        m[1].requires_grad=True\n",
    "\n",
    "n_parameters = sum(p.numel() for p in model.parameters())\n",
    "n_trainables = sum(\n",
    "   p.numel() for p in model.parameters() if p.requires_grad\n",
    ")\n",
    "print(f\"Number of parameters: {n_parameters}\")\n",
    "print(f\"Number of trainable parameters: {n_trainables}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating based on ['albinoni_sonate_da_chiesa_6_(c)icking-archive']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████▌                      | 1/2 [00:48<00:48, 48.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating based on ['anglebert_fugue_3_(c)mccoy']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [01:49<00:00, 54.67s/it]\n",
      "  0%|                                                     | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating based on ['anglebert_fugue_3_(c)mccoy']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████▌                      | 1/2 [00:21<00:21, 21.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating based on ['albinoni_sonate_da_chiesa_6_(c)icking-archive']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:34<00:00, 17.04s/it]\n"
     ]
    }
   ],
   "source": [
    "#comparative generation:\n",
    "generate(2,\"./samples\",seq_len=50,model=origModel,modes=[\"unconditioned\",\"instrument_informed\",\"4_beat\",\"16_beat\"])\n",
    "generate(2,\"./samples2\",seq_len=50,model=firstTrain,modes=[\"unconditioned\",\"instrument_informed\",\"4_beat\",\"16_beat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the model\n",
    "def get_lr_multiplier(\n",
    "    step, warmup_steps, decay_end_steps, decay_end_multiplier\n",
    "):\n",
    "    \"\"\"Return the learning rate multiplier with a warmup and decay schedule.\n",
    "\n",
    "    The learning rate multiplier starts from 0 and linearly increases to 1\n",
    "    after `warmup_steps`. After that, it linearly decreases to\n",
    "    `decay_end_multiplier` until `decay_end_steps` is reached.\n",
    "\n",
    "    \"\"\"\n",
    "    if step < warmup_steps:\n",
    "        return (step + 1) / warmup_steps\n",
    "    if step > decay_end_steps:\n",
    "        return decay_end_multiplier\n",
    "    position = (step - warmup_steps) / (decay_end_steps - warmup_steps)\n",
    "    return 1 - (1 - decay_end_multiplier) * position\n",
    "\n",
    "\n",
    "def train(out_dir,model):\n",
    "    \"\"\"Main function.\"\"\"\n",
    "    # Parse the command-line arguments\n",
    "\n",
    "    # Make sure the output directory exists\n",
    "    pathlib.Path(out_dir).mkdir(exist_ok=True)\n",
    "    pathlib.Path(out_dir+\"/checkpoints\").mkdir(exist_ok=True)\n",
    "    # Get the specified device\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "\n",
    "    # Summarize the model\n",
    "    n_parameters = sum(p.numel() for p in model.parameters())\n",
    "    n_trainables = sum(\n",
    "        p.numel() for p in model.parameters() if p.requires_grad\n",
    "    )\n",
    "    print(f\"Number of parameters: {n_parameters}\")\n",
    "    print(f\"Number of trainable parameters: {n_trainables}\")\n",
    "\n",
    "    # Create the optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), train_args[\"learning_rate\"])\n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
    "        optimizer,\n",
    "        lr_lambda=lambda step: get_lr_multiplier(\n",
    "            step,\n",
    "            train_args[\"lr_warmup_steps\"],\n",
    "            train_args[\"lr_decay_steps\"],\n",
    "            train_args[\"lr_decay_multiplier\"],\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # Create a file to record losses\n",
    "    loss_csv = open(out_dir+\"/loss.csv\", \"w\")\n",
    "    loss_csv.write(\n",
    "        \"step,train_loss,valid_loss,type_loss,beat_loss,position_loss,\"\n",
    "        \"pitch_loss,duration_loss,instrument_loss\\n\"\n",
    "    )\n",
    "    # Initialize variables\n",
    "    step = 0\n",
    "    min_val_loss = float(\"inf\")\n",
    "    if train_args[\"early_stopping\"]:\n",
    "        count_early_stopping = 0\n",
    "\n",
    "    # Iterate for the specified number of steps\n",
    "    train_iterator = iter(train_loader)\n",
    "    while step < train_args[\"steps\"]:\n",
    "\n",
    "        # Training\n",
    "        print(f\"Training...\")\n",
    "        model.train()\n",
    "        recent_losses = []\n",
    "\n",
    "        for batch in (pbar := tqdm.tqdm(range(train_args[\"valid_steps\"]), ncols=80)):\n",
    "            # Get next batch\n",
    "            try:\n",
    "                batch = next(train_iterator)\n",
    "            except StopIteration:\n",
    "                # Reinitialize dataset iterator\n",
    "                train_iterator = iter(train_loader)\n",
    "                batch = next(train_iterator)\n",
    "\n",
    "            # Get input and output pair\n",
    "            seq = batch[\"seq\"].to(device)\n",
    "            mask = batch[\"mask\"].to(device)\n",
    "\n",
    "            # Update the model parameters\n",
    "            optimizer.zero_grad()\n",
    "            loss = model(seq, mask=mask)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                model.parameters(), train_args[\"grad_norm_clip\"]\n",
    "            )\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            # Compute the moving average of the loss\n",
    "            recent_losses.append(float(loss))\n",
    "            if len(recent_losses) > 10:\n",
    "                del recent_losses[0]\n",
    "            train_loss = np.mean(recent_losses)\n",
    "            pbar.set_postfix(loss=f\"{train_loss:8.4f}\")\n",
    "\n",
    "            step += 1\n",
    "\n",
    "        # Release GPU memory right away\n",
    "        del seq, mask\n",
    "\n",
    "        # Validation\n",
    "        print(f\"Validating...\")\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            total_loss = 0\n",
    "            total_losses = [0] * 6\n",
    "            count = 0\n",
    "            for batch in valid_loader:\n",
    "                # Get input and output pair\n",
    "                seq = batch[\"seq\"].to(device)\n",
    "                mask = batch[\"mask\"].to(device)\n",
    "\n",
    "                # Pass through the model\n",
    "                loss, losses = model(seq, return_list=True, mask=mask)\n",
    "\n",
    "                # Accumulate validation loss\n",
    "                count += len(batch)\n",
    "                total_loss += len(batch) * float(loss)\n",
    "                for idx in range(6):\n",
    "                    total_losses[idx] += float(losses[idx])\n",
    "        val_loss = total_loss / count\n",
    "        individual_losses = [l / count for l in total_losses]\n",
    "        print(f\"Validation loss: {val_loss:.4f}\")\n",
    "        print(\n",
    "            f\"Individual losses: type={individual_losses[0]:.4f}, \"\n",
    "            f\"beat: {individual_losses[1]:.4f}, \"\n",
    "            f\"position: {individual_losses[2]:.4f}, \"\n",
    "            f\"pitch: {individual_losses[3]:.4f}, \"\n",
    "            f\"duration: {individual_losses[4]:.4f}, \"\n",
    "            f\"instrument: {individual_losses[5]:.4f}\"\n",
    "        )\n",
    "\n",
    "        # Release GPU memory right away\n",
    "        del seq, mask\n",
    "\n",
    "        # Write losses to file\n",
    "        loss_csv.write(\n",
    "            f\"{step},{train_loss},{val_loss},{individual_losses[0]},\"\n",
    "            f\"{individual_losses[1]},{individual_losses[2]},\"\n",
    "            f\"{individual_losses[3]},{individual_losses[4]},\"\n",
    "            f\"{individual_losses[5]}\\n\"\n",
    "        )\n",
    "\n",
    "        # Save the model\n",
    "        checkpoint_filename = out_dir+\"/checkpoints/\"+f\"model_{step}.pt\"\n",
    "        torch.save(model.state_dict(), checkpoint_filename)\n",
    "        print(f\"Saved the model to: {checkpoint_filename}\")\n",
    "\n",
    "        # Copy the model if it is the best model so far\n",
    "        if val_loss < min_val_loss:\n",
    "            min_val_loss = val_loss\n",
    "            shutil.copyfile(\n",
    "                checkpoint_filename,\n",
    "                out_dir+\"/checkpoints/\"+\"best_model.pt\",\n",
    "            )\n",
    "            # Reset the early stopping counter if we found a better model\n",
    "            if train_args[\"early_stopping\"]:\n",
    "                count_early_stopping = 0\n",
    "        elif train_args[\"early_stopping\"]:\n",
    "            # Increment the early stopping counter if no improvement is found\n",
    "            count_early_stopping += 1\n",
    "\n",
    "        # Early stopping\n",
    "        if (\n",
    "            train_args[\"early_stopping\"]\n",
    "            and count_early_stopping > train_args[\"early_stopping_tolerance\"]\n",
    "        ):\n",
    "            print(\n",
    "                \"Stopped the training for no improvements in \"\n",
    "                f\"{train_args['early_stopping_tolerance']} rounds.\"\n",
    "            )\n",
    "            break\n",
    "\n",
    "    # Log minimum validation loss\n",
    "    print(f\"Minimum validation loss achieved: {min_val_loss}\")\n",
    "\n",
    "    # Save the optimizer states\n",
    "    optimizer_filename = out_dir+\"/checkpoints/\"+f\"optimizer_{step}.pt\"\n",
    "    torch.save(optimizer.state_dict(), optimizer_filename)\n",
    "    print(f\"Saved the optimizer state to: {optimizer_filename}\")\n",
    "\n",
    "    # Save the scheduler states\n",
    "    scheduler_filename = out_dir+\"checkpoints/\"+f\"scheduler_{step}.pt\"\n",
    "    torch.save(scheduler.state_dict(), scheduler_filename)\n",
    "    print(f\"Saved the scheduler state to: {scheduler_filename}\")\n",
    "\n",
    "    # Close the file\n",
    "    loss_csv.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 19944950\n",
      "Number of trainable parameters: 257526\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 1000/1000 [21:22:02<00:00, 76.92s/it, loss=1.7796]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n",
      "Validation loss: 1.3894\n",
      "Individual losses: type=0.0010, beat: 0.0136, position: 0.0387, pitch: 0.1665, duration: 0.1195, instrument: 0.0080\n",
      "Saved the model to: experiment/checkpoints/model_1000.pt\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|████▋                    | 186/1000 [38:38<2:49:06, 12.47s/it, loss=1.4610]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[78], line 75\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(out_dir, model)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 75\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;66;03m# Reinitialize dataset iterator\u001b[39;00m\n",
      "File \u001b[1;32md:\\Programms\\Anaconda\\envs\\mtmt\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 530\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32md:\\Programms\\Anaconda\\envs\\mtmt\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1197\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown_workers()\n\u001b[1;32m-> 1197\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[0;32m   1199\u001b[0m \u001b[38;5;66;03m# Now `self._rcvd_idx` is the batch index we want to fetch\u001b[39;00m\n\u001b[0;32m   1200\u001b[0m \n\u001b[0;32m   1201\u001b[0m \u001b[38;5;66;03m# Check if the next sample has already been generated\u001b[39;00m\n",
      "\u001b[1;31mStopIteration\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[79], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexperiment\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[78], line 79\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(out_dir, model)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;66;03m# Reinitialize dataset iterator\u001b[39;00m\n\u001b[0;32m     78\u001b[0m     train_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(train_loader)\n\u001b[1;32m---> 79\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# Get input and output pair\u001b[39;00m\n\u001b[0;32m     82\u001b[0m seq \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32md:\\Programms\\Anaconda\\envs\\mtmt\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 530\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    533\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    534\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32md:\\Programms\\Anaconda\\envs\\mtmt\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1207\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[0;32m   1206\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1207\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1208\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[0;32m   1210\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32md:\\Programms\\Anaconda\\envs\\mtmt\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1173\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1169\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[0;32m   1170\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[0;32m   1171\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1172\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 1173\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1174\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m   1175\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32md:\\Programms\\Anaconda\\envs\\mtmt\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1011\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    998\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[0;32m    999\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[0;32m   1000\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1008\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[0;32m   1009\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[0;32m   1010\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1011\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1012\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[0;32m   1013\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1014\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[0;32m   1015\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[0;32m   1016\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[1;32md:\\Programms\\Anaconda\\envs\\mtmt\\lib\\multiprocessing\\queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[0;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[1;32md:\\Programms\\Anaconda\\envs\\mtmt\\lib\\multiprocessing\\connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[1;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Programms\\Anaconda\\envs\\mtmt\\lib\\multiprocessing\\connection.py:330\u001b[0m, in \u001b[0;36mPipeConnection._poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_got_empty_message \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m    328\u001b[0m             _winapi\u001b[38;5;241m.\u001b[39mPeekNamedPipe(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 330\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32md:\\Programms\\Anaconda\\envs\\mtmt\\lib\\multiprocessing\\connection.py:879\u001b[0m, in \u001b[0;36mwait\u001b[1;34m(object_list, timeout)\u001b[0m\n\u001b[0;32m    876\u001b[0m                 ready_objects\u001b[38;5;241m.\u001b[39madd(o)\n\u001b[0;32m    877\u001b[0m                 timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 879\u001b[0m     ready_handles \u001b[38;5;241m=\u001b[39m \u001b[43m_exhaustive_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwaithandle_to_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;66;03m# request that overlapped reads stop\u001b[39;00m\n\u001b[0;32m    882\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ov \u001b[38;5;129;01min\u001b[39;00m ov_list:\n",
      "File \u001b[1;32md:\\Programms\\Anaconda\\envs\\mtmt\\lib\\multiprocessing\\connection.py:811\u001b[0m, in \u001b[0;36m_exhaustive_wait\u001b[1;34m(handles, timeout)\u001b[0m\n\u001b[0;32m    809\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    810\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m L:\n\u001b[1;32m--> 811\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWaitForMultipleObjects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    812\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;241m==\u001b[39m WAIT_TIMEOUT:\n\u001b[0;32m    813\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(\"experiment\",model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mtmt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
